\chapter{Методы интерпретации}

В этой главе мы кратко представим существующие подходы интерпретации моделей машинного обучения.

Следует представить некоторую категоризацию имеющихся методов. Популярным подходом является разделение методов на три широкие группы: локальные, глобальные объяснения и объяснения отдельных классов. \textbf{Локальные объяснения} предназначены для ретроактивного объяснения результатов только для одного заданного наблюдения. \textbf{Глобальные объяснения} пытаются суммаризовать информацию о всей модели целиком, но обычно по отношению только к одному выбранному аспекту. \textbf{Классовые объяснения} также пытаются объяснить всю модель, но только по отношению работы с одним конкретным классом.

% TODO: more
Также в \cite{madsen_post-hoc_2021} дополнительно проводится различие между внутренними (intrinsic) и post-hoc методами. Внутренние методы в своей работы полагаются на устройство рассматриваемой модели. Зачастую это относится к моделям, которые в силу свое простой структуры изначально интерпретируемы. Хотя и сушествуют примеры для более сложных моделей, например, Attention-слои, при которых мы можем судить о важности определенных токенов при генерации предсказания.
Post-hoc же методы предоставляют объяснения только после того как модель обучена и зачастую эти методы агностичны к рассматриваемой модели.

Также методы инетрпретации различаются и по виду их результата. Это может быть обощающая статистика по входным признакам (пример - feature importance в случайном лесе), некоторая обощающая визуализация по входным признакам, интерпретация по весам модели (для линейной регрессии и решающего дерева), некоторое противоположное или похожее наблюдение (контрфакты и adversarial-примеры) или аппроксимация рассматриваемой модели через более простую внутрене интерпретируемую модель.

\section Локальные объяснения

\section Глобальные объяснения